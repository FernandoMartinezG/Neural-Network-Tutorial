{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks for number generation\n",
    "First we import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set a variable **device** that directs to our GPU in case that we have one available in our computer. The following will assign the GPU to **device** in case that we have one, otherwise the device will point to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to load all the images of numbers from the numbers file in the same folder (after we decompressed the file). The array obtained can be saved in a file in order to access it easier next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 3354.53it/s]\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 64\n",
    "images = []\n",
    "for img in tqdm(glob.glob(\"numbers/*.png\")):\n",
    "    n = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    n = cv2.resize(n, (IMG_SIZE, IMG_SIZE))\n",
    "    n = np.asarray(n.transpose(2,0,1))\n",
    "    images.append(n)\n",
    "# Save the array\n",
    "np.save(\"training_dat.npy\", images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded array is indeed an array with 10000 MNIST number of 64x64 pixels. We also have three channels of color (BGR), although since the image is in black and white, we could use only one channel, but this way we can tackle problems that can appear when treating images with more than one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3, 64, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot examples of our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23a8066f0c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# We use the transpose to switch the dimensions of the NumPy array so that the plt.imshow displays it correctly\n",
    "plt.imshow(images[0].transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the array we just need to use the following line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3, 64, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = np.load(\"training_dat.npy\", allow_pickle=True)\n",
    "np.shape(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to normalise the array between -1 and 1 and create a PyTorch tensor with it. We can check if the tensor created is stored in the GPU or not with **is_cuda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 20668.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Change to pytorch tensor format\n",
    "X = torch.Tensor([((i/255.)*2 - 1) for i in tqdm(training_data)]).to(device)\n",
    "print(X.is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is defining the Generator and Discriminator neural networks. They will be made of convolutional layers. We also create a function to initialise the parameters of the networks sampling a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Generator and Discriminator Neural Networks\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "class G(nn.Module):\n",
    "    def __init__(self):\n",
    "            super(G, self).__init__()\n",
    "            self.main = nn.Sequential(\n",
    "                nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.LeakyReLU(0.2, inplace = True),\n",
    "                nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.LeakyReLU(0.2, inplace = True),\n",
    "                nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.LeakyReLU(0.2, inplace = True),\n",
    "                nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.2, inplace = True),\n",
    "                nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "    def forward(self, input):\n",
    "            output = self.main(input)\n",
    "            return output\n",
    "netG = G()\n",
    "netG.apply(weights_init)\n",
    "class D(nn.Module):\n",
    "    def __init__(self):\n",
    "            super(D, self).__init__()\n",
    "            self.main = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, 4, 2, 1, bias = False),\n",
    "                nn.LeakyReLU(0.2, inplace = True),\n",
    "                nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.LeakyReLU(0.2, inplace = True),\n",
    "                nn.Conv2d(128, 256, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.LeakyReLU(0.2, inplace = True),\n",
    "                nn.Conv2d(256, 512, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.LeakyReLU(0.2, inplace = True),\n",
    "                nn.Conv2d(512, 1, 4, 1, 0, bias = False),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "    def forward(self, input):\n",
    "            output = self.main(input)\n",
    "            return output.view(-1)\n",
    "netD = D()\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is defining the loss function and the optimizers. In this case we will use the Binary Cross Entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to load the neural networks to the GPU in case that we are using one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "netD.to(device)\n",
    "print(next(netD.parameters()).is_cuda)\n",
    "netG.to(device)\n",
    "print(next(netG.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/150][12/156] Loss_D: 0.0460 Loss_G: 8.3039. Total images = 768\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-cd3ddd247265>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0merrD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrD_real\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0merrD_fake\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0merrD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0moptimizerD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mnetG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\py64_37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\py64_37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 150\n",
    "BATCH_SIZE = 64\n",
    "for epoch in range(0, EPOCHS):\n",
    "    for i in range(0, len(X), BATCH_SIZE):\n",
    "        netD.zero_grad()\n",
    "\n",
    "        real = X[i:i+BATCH_SIZE]\n",
    "        target = torch.ones(real.size()[0]).to(device)\n",
    "        output = netD(real)\n",
    "        errD_real = criterion(output, target)\n",
    "\n",
    "        noise = torch.randn(real.size()[0], 100, 1, 1).to(device)\n",
    "        fake = netG(noise)\n",
    "        target = torch.zeros(real.size()[0]).to(device)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, target)\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        errD.backward()\n",
    "        optimizerD.step()\n",
    "        netG.zero_grad()\n",
    "        target = torch.ones(real.size()[0]).to(device)\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, target)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f. Total images = %d' % (epoch, EPOCHS, (i+BATCH_SIZE)/BATCH_SIZE, len(X)/BATCH_SIZE, errD.data, errG.data, i+BATCH_SIZE), end=\"\\r\")\n",
    "        if i % (53*BATCH_SIZE) == 0:\n",
    "            torch.save(netD.state_dict(), 'trained_netD_CDimageGAN.pt')\n",
    "            torch.save(netG.state_dict(), 'trained_netG_CDimageGAN.pt')\n",
    "            vutils.save_image(real, '%s/real_samples.png' % \"./results\", normalize = True)\n",
    "            fake = netG(noise)\n",
    "            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d_%03d.png' % (\"./results\", epoch, i+BATCH_SIZE), normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained parameters for each neural network can be loaded with the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD.load_state_dict(torch.load('trained_netD_CDimageGAN.pt'))\n",
    "netD.eval()\n",
    "netG.load_state_dict(torch.load('trained_netG_CDimageGAN.pt'))\n",
    "netG.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
